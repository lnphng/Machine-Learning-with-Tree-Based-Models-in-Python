{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Tuning \n",
    "- The hyperparameters of a machine learning model are parameters that are not learned from data. They should be set prior to fitting the model to the training set to tune the hyperparameters of a tree-based model using grid search cross validation.\n",
    "\n",
    "### Tuning a CART's hyperparameters\n",
    "#### Hyperparameters\n",
    "Machine learning model:\n",
    "- parameters: learned from data\n",
    "    - CART example: `split-point` of a node,  `split- feature` of a node,  ...\n",
    "- hyperparameters: not learned from data,  set prior to training\n",
    "    - CART example:  `max_depth`,   `min_samples_leaf`,  `splitting criterion`...\n",
    "    \n",
    "#### What is hyperparameter tuning?\n",
    "- Problem: search for a set of optimal hyperparameters for a learning algorithm.\n",
    "- Solution: find a set of optimal hyperparameters that results in an optimal model.\n",
    "- Optimal model: yields an optimal score.\n",
    "- Score: in `sklearn` defaults to accuracy (classification) and R  (regression).\n",
    "- Cross validation is used to estimate the generalization performance.\n",
    "\n",
    "#### Why tune hyperparameters?\n",
    "- In  `sklearn`,  a model's default hyperparameters are not optimal for all problems.\n",
    "- Hyperparameters should be tuned to obtain the best model performance.\n",
    "\n",
    "#### Grid search cross validation\n",
    "- Manually set a grid of discrete hyperparameter values.\n",
    "    - $max\\_depth  = {2, 3, 4},$\n",
    "    - $min\\_samples\\_leaf  = {0. 05,  0. 1}$\n",
    "- Set a metric for scoring model performance.\n",
    "    - hyperparameter space = ${ (2, 0. 05) ,  (2, 0. 1) ,  (3, 0. 05),  . . .  }$\n",
    "- Search exhaustively through the grid.\n",
    "- For each set of hyperparameters,  evaluate each model's CV score.\n",
    "    - CV scores = { $score_{(2, 0. 05)}$  ,  . . .  }\n",
    "- The optimal hyperparameters are those of the model achieving the best CV score.\n",
    "    - optimal hyperparameters = set of hyperparameters corresponding to the best CV score\n",
    "\n",
    "#### Example: \n",
    "Hyperparameter of `DecisionTreeClassifier` \n",
    "```\n",
    "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
    "            splitter='best')\n",
    "          ```\n",
    "=> `mean_features` not a Hyperparameter of `DecisionTreeClassifier`\n",
    "#### Doing\n",
    "- Inspecting the hyperparameters of a CART in `sklearn`\n",
    "- Extracting the best hyperparameters\n",
    "    - Set the tree's hyperparameter grid\n",
    "    - Define params_dt\n",
    "    - Evaluate the optimal tree\n",
    "    - Compute the test set ROC AUC score.\n",
    "- Extracting the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "SEED =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=1, splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset\n",
    "liver = pd.read_csv('indian_liver_patient/indian_liver_patient_preprocessed.csv', index_col = 0)\n",
    "X = liver.drop('Liver_disease', axis = 1)\n",
    "y = liver['Liver_disease']\n",
    "\n",
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, random_state=1,\n",
    "            splitter='best')\n",
    "\n",
    "\n",
    "#split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=1, splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [2, 3, 4],\n",
       "                         'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the tree's hyperparameter grid\n",
    "# Define params_dt\n",
    "params_dt = {\n",
    "'max_depth': [2,3, 4],\n",
    "'min_samples_leaf': [0.12, 0.14, 0.16, 0.18] }\n",
    "\n",
    "# performing the grid search.\n",
    "## Import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "#compute the test set ROC AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      " DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=0.14, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=1, splitter='best')\n",
      "Test set ROC AUC score: 0.731\n"
     ]
    }
   ],
   "source": [
    "# Import roc_auc_score from sklearn.metrics\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "print('Best estimator:\\n', best_model)\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning an RF's Hyperparameters\n",
    "#### Random Forests Hyperparameters\n",
    "- CART hyperparameters\n",
    "- number of estimators\n",
    "- bootstrap\n",
    "#### Tuning is expensive\n",
    "- Hyperparameter tuning:\n",
    "    - computationally expensive,\n",
    "    - sometimes leads to very slight improvement,\n",
    "- Weight the impact of tuning on the whole project\n",
    "\n",
    "#### Doing:\n",
    "- Instantiate RF\n",
    "- Instantiate GridsearchCV\n",
    "- Evaluating the test set RMSE of the best model\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   40.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:   40.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': ['log2', 'auto', 'sqrt'],\n",
       "                         'min_samples_leaf': [2, 10, 30],\n",
       "                         'n_estimators': [100, 350, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the dictionary 'params_rf'\n",
    "params_rf = {\n",
    "   'max_features': ['log2', 'auto', 'sqrt'],\n",
    " 'min_samples_leaf': [2, 10, 30],\n",
    " 'n_estimators': [100, 350, 500],\n",
    " }\n",
    "\n",
    "# Import GridSearchCV\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "# Instantiate grid_rf\n",
    "grid_rf = GridSearchCV(estimator=rf,\n",
    "                       param_grid=params_rf,\n",
    "                       scoring='neg_mean_squared_error',\n",
    "                       cv=3,\n",
    "                       verbose=1,\n",
    "                       n_jobs=-1)\n",
    "bike = pd.read_csv('bikes.csv')\n",
    "X = bike[['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'instant',\n",
    "       'mnth', 'yr', 'Clear to partly cloudy', 'Light Precipitation', 'Misty']]\n",
    "y = bike['cnt']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "# Fit with train set\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE of best model: 51.321\n"
     ]
    }
   ],
   "source": [
    "# Import mean_squared_error from sklearn.metrics as MSE \n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_rf.best_estimator_\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute rmse_test\n",
    "rmse_test = MSE(y_test,y_pred)**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test RMSE of best model: {:.3f}'.format(rmse_test)) "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
