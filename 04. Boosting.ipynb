{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting\n",
    "Boosting refers to an ensemble method in which several models are trained sequentially with each model learning from the errors of its predecessors. \n",
    "### Boosting\n",
    "- Boosting: Ensemble method combining several weak learners to form a strong learner .\n",
    "- Weak learner: Model doing slightly better than random guessing.\n",
    "- Example of weak learner: Decision stump (CART whose maximum depth is 1).\n",
    "- Train an ensemble of predictors sequentially .\n",
    "- Each predictor tries to correct its predecessor .\n",
    "- Most popular boosting methods:\n",
    "    - AdaBoost,\n",
    "    - Gradient Boosting.\n",
    "\n",
    "### AdaBoost\n",
    "- Stands for Adaptive Boosting.\n",
    "- Each predictor pays more attention to the instances wrongly predicted by its predecessor .\n",
    "- Achieved by changing the weights of training instances.\n",
    "- Each predictor is assigned a coeficient α.\n",
    "- α depends on the predictor's training error .\n",
    "-AdaBoost: Prediction\n",
    "    - Classification:\n",
    "        - Weighted majority voting.\n",
    "        - In sklearn:  `AdaBoostClassifier` .\n",
    "    - Regression:\n",
    "        - Weighted average.\n",
    "        - In sklearn:  `AdaBoostRegressor`.\n",
    "- Define the AdaBoost classifier\n",
    "    - Dataset: the Indian Liver Patient dataset \n",
    "    - Task: \n",
    "        - Predict whether a patient suffers from a liver disease using 10 features including Albumin, age and gender. \n",
    "        - with AdaBoost ensemble to perform the classification task. \n",
    "        - using the ROC AUC score as a metric instead of accuracy.\n",
    "    - Doing:\n",
    "        - Dataset\n",
    "        - Instantiate dt,ada\n",
    "        - Predict the probabilities of obtaining the positive class in the test set.\n",
    "        - Extract these probabilities by slicing all the values in the second column\n",
    "        - Evaluate ada's ROC AUC score, a binary classifier can be determined using the `roc_auc_score()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "SEED =1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_std</th>\n",
       "      <th>Total_Bilirubin_std</th>\n",
       "      <th>Direct_Bilirubin_std</th>\n",
       "      <th>Alkaline_Phosphotase_std</th>\n",
       "      <th>Alamine_Aminotransferase_std</th>\n",
       "      <th>Aspartate_Aminotransferase_std</th>\n",
       "      <th>Total_Protiens_std</th>\n",
       "      <th>Albumin_std</th>\n",
       "      <th>Albumin_and_Globulin_Ratio_std</th>\n",
       "      <th>Is_male_std</th>\n",
       "      <th>Liver_disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.247403</td>\n",
       "      <td>-0.420320</td>\n",
       "      <td>-0.495414</td>\n",
       "      <td>-0.428870</td>\n",
       "      <td>-0.355832</td>\n",
       "      <td>-0.319111</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.147390</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>1.218936</td>\n",
       "      <td>1.423518</td>\n",
       "      <td>1.675083</td>\n",
       "      <td>-0.093573</td>\n",
       "      <td>-0.035962</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>-0.648461</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.062306</td>\n",
       "      <td>0.640375</td>\n",
       "      <td>0.926017</td>\n",
       "      <td>0.816243</td>\n",
       "      <td>-0.115428</td>\n",
       "      <td>-0.146459</td>\n",
       "      <td>0.478274</td>\n",
       "      <td>0.203446</td>\n",
       "      <td>-0.178707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.815511</td>\n",
       "      <td>-0.372106</td>\n",
       "      <td>-0.388807</td>\n",
       "      <td>-0.449416</td>\n",
       "      <td>-0.366760</td>\n",
       "      <td>-0.312205</td>\n",
       "      <td>0.293722</td>\n",
       "      <td>0.329431</td>\n",
       "      <td>0.165780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.679294</td>\n",
       "      <td>0.093956</td>\n",
       "      <td>0.179766</td>\n",
       "      <td>-0.395996</td>\n",
       "      <td>-0.295731</td>\n",
       "      <td>-0.177537</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>-0.930414</td>\n",
       "      <td>-1.713237</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age_std  Total_Bilirubin_std  Direct_Bilirubin_std  \\\n",
       "0  1.247403            -0.420320             -0.495414   \n",
       "1  1.062306             1.218936              1.423518   \n",
       "2  1.062306             0.640375              0.926017   \n",
       "3  0.815511            -0.372106             -0.388807   \n",
       "4  1.679294             0.093956              0.179766   \n",
       "\n",
       "   Alkaline_Phosphotase_std  Alamine_Aminotransferase_std  \\\n",
       "0                 -0.428870                     -0.355832   \n",
       "1                  1.675083                     -0.093573   \n",
       "2                  0.816243                     -0.115428   \n",
       "3                 -0.449416                     -0.366760   \n",
       "4                 -0.395996                     -0.295731   \n",
       "\n",
       "   Aspartate_Aminotransferase_std  Total_Protiens_std  Albumin_std  \\\n",
       "0                       -0.319111            0.293722     0.203446   \n",
       "1                       -0.035962            0.939655     0.077462   \n",
       "2                       -0.146459            0.478274     0.203446   \n",
       "3                       -0.312205            0.293722     0.329431   \n",
       "4                       -0.177537            0.755102    -0.930414   \n",
       "\n",
       "   Albumin_and_Globulin_Ratio_std  Is_male_std  Liver_disease  \n",
       "0                       -0.147390            0              1  \n",
       "1                       -0.648461            1              1  \n",
       "2                       -0.178707            1              1  \n",
       "3                        0.165780            1              1  \n",
       "4                       -1.713237            1              1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "liver = pd.read_csv('indian_liver_patient/indian_liver_patient_preprocessed.csv', index_col = 0)\n",
    "X = liver.drop('Liver_disease', axis = 1)\n",
    "y = liver['Liver_disease']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "\n",
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "stratify=y,\n",
    "random_state=SEED)\n",
    "\n",
    "liver.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Import DecisionTreeClassifier\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import AdaBoostClassifier\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "\n",
    "# Instantiate ada\n",
    "ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)\n",
    "\n",
    "# Fit ada to the training set\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Compute the probabilities of obtaining the positive class\n",
    "y_pred_proba = ada.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Import roc_auc_score\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Evaluate test-set roc_auc_score\n",
    "ada_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print roc_auc_score\n",
    "print('ROC AUC score: {:.2f}'.format(ada_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting\n",
    "#### Gradient Boosted Trees\n",
    "- Sequential correction of predecessor's errors.\n",
    "- Does not tweak the weights of training instances.\n",
    "- Fit each predictor is trained using its predecessor's residual errors as labels.\n",
    "- Gradient Boosted T rees: a CART is used as a base learner\n",
    "#### Gradient Boosted T rees: Prediction\n",
    "- Regression:\n",
    "    - $y_{pred} = y + ηr_1 + ... + ηr_N$\n",
    "    - In sklearn:  GradientBoostingRegressor .\n",
    "- Classi×cation:\n",
    "    - In sklearn:  GradientBoostingClassifier .\n",
    "#### Example\n",
    "- Dataset:  Bike Sharing Demand\n",
    "- Tasks: \n",
    "    - to predict the bike rental demand using historical weather data from the Capital Bikeshare program in Washington, D.C.. \n",
    "    - using a gradient boosting regressor.\n",
    "- Doing:\n",
    "    - Dataset\n",
    "    - Instantiate a gradient boosting regressor \n",
    "    - Train the dataset\n",
    "    - Evaluate the GB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset\n",
    "bike = pd.read_csv('bikes.csv')\n",
    "\n",
    "X = bike[['hr', 'holiday', 'workingday', 'temp', 'hum', 'windspeed', 'instant',\n",
    "       'mnth', 'yr', 'Clear to partly cloudy', 'Light Precipitation', 'Misty']]\n",
    "y = bike['cnt']\n",
    "\n",
    "# Split data into 80% train and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GB regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of gb: 50.726\n"
     ]
    }
   ],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate gb\n",
    "gb = GradientBoostingRegressor(max_depth=4, \n",
    "            n_estimators=200,\n",
    "            random_state=2)\n",
    "# Fit gb to the training set\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "# Compute MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_test_gb = mse_test**(1/2)\n",
    "\n",
    "# Print RMSE\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Boosting (SGB)\n",
    "\n",
    "#### Gradient Boosting\n",
    "- GB involves an exhaustive search procedure.\n",
    "- Each CART is trained to **find the best split points and features**.\n",
    "- May lead to CARTs using the same split points and maybe the same features.\n",
    "\n",
    "#### Stochastic Gradient Boosting\n",
    "- Each tree is trained on **a random subset of rows** of the training data.\n",
    "- The sampled instances (40%-80% of the training set) are sampled without replacement.\n",
    "- Features are sampled (without replacement) when choosing split points.\n",
    "- Result: further ensemble diversity .\n",
    "- Effect: adding further variance to the ensemble of trees.\n",
    "\n",
    "#### Example: Regression with SGB\n",
    "- Dataset Bike Sharing Demand. \n",
    "- Task: solve this bike count regression problem using stochastic gradient boosting.\n",
    "- Doing\n",
    "    - Dataset\n",
    "    - Train the SGB regressor\n",
    "    - Predict the test set labels.\n",
    "    - Evaluate test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE of sgbr: 54.604\n",
      "Test set RMSE of gb: 50.726\n",
      "\n",
      "The stochastic gradient boosting regressor achieves a lower test set RMSE\n",
      "than the gradient boosting regressor, which was 50.726\n"
     ]
    }
   ],
   "source": [
    "# Import GradientBoostingRegressor\n",
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Instantiate sgbr\n",
    "sgbr = GradientBoostingRegressor(max_depth=4, \n",
    "            subsample=0.9,\n",
    "            max_features=0.75,\n",
    "            n_estimators=200,                                \n",
    "            random_state=2)\n",
    "# Fit sgbr to the training set\n",
    "sgbr.fit(X_train, y_train)\n",
    "\n",
    "# Predict test set labels\n",
    "y_pred = sgbr.predict(X_test)\n",
    "\n",
    "# Import mean_squared_error as MSE\n",
    "#from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "# Compute test set MSE\n",
    "mse_test = MSE(y_test, y_pred)\n",
    "\n",
    "# Compute test set RMSE\n",
    "rmse_test_sgb = mse_test**(1/2)\n",
    "\n",
    "# Print rmse_test\n",
    "print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test_sgb))\n",
    "print('Test set RMSE of gb: {:.3f}'.format(rmse_test_gb))\n",
    "\n",
    "print('\\nThe stochastic gradient boosting regressor achieves a lower test set RMSE\\\n",
    "\\nthan the gradient boosting regressor, which was {:.3f}'.format(rmse_test_gb) )"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
